{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a05ff0-54f1-4429-8f68-53297b6ade27",
   "metadata": {},
   "source": [
    "#### Carpeta del proyecto y almacenaje de ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039f720-ed79-4095-91f7-3a461c93d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utm\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Project folder and file paths\n",
    "\n",
    "# Define the name of the project folder and create it in case it does not exists yet\n",
    "folder = \"name_of_project_folder\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "print(f\"The project will be saved in the folder: '{folder}'\")\n",
    "\n",
    "# Define the center coordinates of the project\n",
    "latitud = 40.801706\n",
    "longitud = -0.839873\n",
    "print(f\"The center coordinates of the project are the following: Lat '{latitud}', Lon '{longitud}'\")\n",
    "\n",
    "# Define the coordinates file name and path\n",
    "file_name_coord = \"coordinates_gmaps.csv\"\n",
    "file_path_coord = os.path.join(folder, file_name_coord)\n",
    "\n",
    "# Define the roboflow results file name and path\n",
    "file_name_results = \"detections_rf.csv\"\n",
    "file_path_results = os.path.join(folder, file_name_results)\n",
    "\n",
    "# Define the weather file name and path\n",
    "file_name_weather = \"weather_pvgis.csv\"\n",
    "file_path_weather = os.path.join(folder, file_name_weather)\n",
    "\n",
    "# Define the pdc prediction file name and path\n",
    "file_name_predictions_pdc = \"predictions_pdc.csv\"\n",
    "file_path_predictions_pdc = os.path.join(folder, file_name_predictions_pdc)\n",
    "\n",
    "# Define the eac prediction file name and path\n",
    "file_name_predictions_eac = \"predictions_pvlib_180_10.csv\"\n",
    "file_path_predictions_eac = os.path.join(folder, file_name_predictions_eac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8886c-330c-4218-9f9d-69628baee7a6",
   "metadata": {},
   "source": [
    "### Barrido imágenes GOOGLE MAPS STATIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6d57e-b756-4bc4-ad6f-22b9061bd558",
   "metadata": {},
   "source": [
    "#### Definición de mallado y coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a7696-698e-4743-9387-8206b4960413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to get google maps images of a specified location and a given area using \n",
    "# Google Static Maps API\n",
    "\n",
    "# Define zoom an size of the images\n",
    "zoom = 19  # zoom level\n",
    "size = \"400x400\"  # image size\n",
    "api_key_gmaps = \"api_key_gmaps\"  # enter your api key here\n",
    "\n",
    "# Define center coordinates of the grid, equidistant from all edges of the grid\n",
    "latitud = latitud\n",
    "longitud = longitud\n",
    "print(f\"The center coordinates of the grid are the following: Lat '{latitud}', Lon '{longitud}'\")\n",
    "\n",
    "# Define area of the grid and related parameters\n",
    "area_km2 = 1\n",
    "area_m2 = area_km2 * 1000000\n",
    "print(f\"The defined area of the grid is '{area_km2}' km2\")\n",
    "\n",
    "square_size = 95 # depends on the zoom level of the image, defined in meters, measured in GMAPS (zoom 19 - size 95m)\n",
    "grid_size = int (np.ceil((np.sqrt(area_m2) / square_size)))\n",
    "num_images = np.square(grid_size) # Number of images for downloading and processing\n",
    "area_evaluated_km2 = np.square(square_size * grid_size) / 1000000\n",
    "\n",
    "print(f\"The grid size is '{grid_size}' and the total number of images for processing will be '{num_images}'\")\n",
    "print(f\"The total area evaluated is '{area_evaluated_km2}' km2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c5677-0791-4c56-ac4e-b6df10d1d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the grid coordinates depending on the desired sweep area\n",
    "\n",
    "def crear_cuadricula(x_centro, y_centro, square_size, grid_size):\n",
    "    # Calcular el desplazamiento para la cuadrícula\n",
    "    desplazamiento = square_size * (grid_size // 2)\n",
    "\n",
    "    # List to save the square centers\n",
    "    centros = []\n",
    "\n",
    "    # Loop to generate the grid square centers\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            # Calculate the coordinates of the grid square centers\n",
    "            x = x_centro + (i - (grid_size // 2)) * square_size\n",
    "            y = y_centro + (j - (grid_size // 2)) * square_size\n",
    "            \n",
    "            # Save the coordinates of the grid square centers\n",
    "            centros.append((x, y))\n",
    "    \n",
    "    return centros\n",
    "\n",
    "# Obtaining UTM coordinates from the center of the defined main square \n",
    "utmcoord = utm.from_latlon(latitud, longitud)\n",
    "x_centro = utmcoord[0]  # Primer valor del resultado (coordenada x)\n",
    "y_centro = utmcoord[1]  # Segundo valor del resultado (coordenada y)\n",
    "\n",
    "\n",
    "# Obtaining UTM coordinates of the grid square centers \n",
    "centros_cuadricula_utm = crear_cuadricula(x_centro, y_centro, square_size, grid_size)\n",
    "# print(centros_cuadricula_utm)\n",
    "print(f\"The UTM coordinates of the grid images have been calculated\")\n",
    "\n",
    "# Function to convert UTM coordinates to latitud and longitude\n",
    "def utm_a_latlon(x_utm, y_utm):\n",
    "    # Define UTM zone and hemispheric letter\n",
    "    zona_utm = 30\n",
    "    letra_hemisferica = 'T'\n",
    "    \n",
    "    lat, lon = utm.to_latlon(x_utm, y_utm, zona_utm, letra_hemisferica)\n",
    "    \n",
    "    return lat, lon\n",
    "\n",
    "# Convert UTM coordinates to latitud and longitude\n",
    "centros_cuadricula_latlon = [utm_a_latlon(x_utm, y_utm) for x_utm, y_utm in centros_cuadricula_utm]\n",
    "# print (centros_cuadricula_latlon)\n",
    "print(f\"The Lat, Lon coordinates of the grid images have been calculated\")\n",
    "\n",
    "# Save the coordinates grid square centers\n",
    "coordinates = centros_cuadricula_latlon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf36418-4ef2-4a7f-a620-6fe72346bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the coordinates DataFrame\n",
    "data_coord = {\n",
    "    'center_lat': [latitud] * len(coordinates),\n",
    "    'center_lon': [longitud] * len(coordinates),\n",
    "    'image': [f'image_{i}' for i in range(len(coordinates))],\n",
    "    'lat': [coord[0] for coord in coordinates],\n",
    "    'lon': [coord[1] for coord in coordinates]\n",
    "}\n",
    "df_coord = pd.DataFrame(data_coord)\n",
    "\n",
    "print(f\"The coordinates dataframe has been created\")\n",
    "\n",
    "print(df_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f800c-d258-4215-aa8f-09f95be87aaf",
   "metadata": {},
   "source": [
    "#### Almacenar fichero de coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47595dd-8fe9-4cad-892a-f62d7ff3e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the coordinates DataFrame\n",
    "\n",
    "# Save the DataFrame in a CSV in its file path\n",
    "df_coord.to_csv(file_path_coord, index=False)\n",
    "\n",
    "print(f\"CSV file saved in '{folder}/{file_name_coord}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee7faa-5980-4b06-8cb4-42400a545fd8",
   "metadata": {},
   "source": [
    "#### Descarga de imágenes API GMAPS STATIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9cb13b-b93e-41fa-90f8-b11e44b7c59d",
   "metadata": {},
   "source": [
    "**NO CORRER SI NO SE QUIERE HACER USO DE LA API DE GOOGLE MAPS STATIC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a0b97-d445-4154-8bf4-fecfdba09d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download images for each of the grid center\n",
    "def download_images_for_grid(coordinates, zoom, size, api_key_gmaps):\n",
    "       \n",
    "    url = \"https://maps.googleapis.com/maps/api/staticmap\"\n",
    "    for i, coord in enumerate(coordinates):\n",
    "        center = f\"{coord[0]}, {coord[1]}\"\n",
    "        r = requests.get(f'{url}?center={center}&zoom={zoom}&size={size}&maptype=satellite&key={api_key_gmaps}')\n",
    "        image_path = os.path.join(folder, f'image_{i}.png')\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "# Download images for each of the grid center\n",
    "download_images_for_grid(coordinates, zoom, size, api_key)\n",
    "print(f\"Images saved in '{folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8497c-7242-4916-80d1-28ae82ccc7f9",
   "metadata": {},
   "source": [
    "### Detección Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a0b07-f305-4bf7-bbc1-3e4d599437a1",
   "metadata": {},
   "source": [
    "#### Definición del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d64d6-2f83-48ee-be26-890f367a5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import matplotlib.pyplot as plt\n",
    "from skspatial.objects import Vector, Point\n",
    "from skspatial.measurement import area_signed\n",
    "\n",
    "from inference_sdk import InferenceHTTPClient, InferenceConfiguration\n",
    "\n",
    "import supervision as sv\n",
    "import cv2\n",
    "\n",
    "# https://docs.roboflow.com/deploy/hosted-api/custom-models/object-detection\n",
    "# https://universe.roboflow.com/whereareyousolarpanel/solar-pv-panel-detection/model/3\n",
    "\n",
    "API_KEY_ROBOFLOW = \"api_key_roboflow\"\n",
    "THRESHOLD = 0.7\n",
    "\n",
    "# 0-Instalar Docker Desktop https://docs.docker.com/desktop/install/windows-install/\n",
    "# 1-Abrir Docker (cerrar asegurandose que sigue en segundo plano (icono presente))\n",
    "# 2-Lanzar máquina virtual desde cmd: inference server start\n",
    "# 3-Lanzar script\n",
    "\n",
    "client = InferenceHTTPClient(\n",
    "    api_url=\"http://localhost:9001\", # Opción docker desktop\n",
    "    #api_url=\"https://detect.roboflow.com\"   -> Acceso a RoboFlow hosted, opción de pago (1000 detecciones/mes)\n",
    "    api_key=API_KEY_ROBOFLOW\n",
    ")\n",
    "\n",
    "client.configure(InferenceConfiguration(confidence_threshold=THRESHOLD))\n",
    "\n",
    "def process_image(file_image):\n",
    "    results = client.infer(file_image, model_id=\"solar-pv-panel-detection/3\")\n",
    "    labels = [item[\"class\"] for item in results[\"predictions\"]]\n",
    "    detections = sv.Detections.from_inference(results)\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "    mask_annotator = sv.MaskAnnotator() # MaskAnnotator: draw mask - BoundingBoxAnnotator: draw bounding box\n",
    "\n",
    "    image = cv2.imread(file_image) # to reed loacl file\n",
    "    annotated_image = mask_annotator.annotate(scene=image, detections=detections)\n",
    "    # annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "    # Save annotated image\n",
    "    output_image_path = f\"{os.path.splitext(file_image)[0]}_w.png\" # w for written (annotated) image\n",
    "    cv2.imwrite(output_image_path, annotated_image)\n",
    "    print(f\"Processed {file_image}, saved annotated image to {output_image_path}\")\n",
    "\n",
    "    return results, detections\n",
    "\n",
    "print(f\"Ready for image processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91119c9d-9c06-45ca-bb6a-7a3dc8be1567",
   "metadata": {},
   "source": [
    "#### Procesado de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92072c-85ab-4c7f-84d5-d96e1f682ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process multiple images locally saved\n",
    "\n",
    "# DataFrame to save results\n",
    "df_results_rf = pd.DataFrame(columns=[\"image_name\", \"coordinates\", \"area_rf\", \"orientation_rf\"])\n",
    "\n",
    "for i in range(num_images):\n",
    "    file_image = os.path.join(folder, f\"image_{i}.png\")\n",
    "    if os.path.exists(file_image):\n",
    "        results, detections = process_image(file_image)\n",
    "\n",
    "        for idx, prediction in enumerate(results['predictions']):\n",
    "            points = pd.DataFrame(prediction['points'])\n",
    "\n",
    "            pto_max_x = points.iloc[points.idxmax().x]\n",
    "            pto_max_y = points.iloc[points.idxmax().y]\n",
    "            pto_min_x = points.iloc[points.idxmin().x]\n",
    "            pto_min_y = points.iloc[points.idxmin().y]\n",
    "\n",
    "            dist_xmax_ymax = Point([pto_max_x.x, pto_max_x.y]).distance_point([pto_max_y.x, pto_max_y.y])\n",
    "            dist_xmax_ymin = Point([pto_max_x.x, pto_max_x.y]).distance_point([pto_min_y.x, pto_min_y.y])\n",
    "\n",
    "            v1 = Vector.from_points([pto_max_x.x, pto_max_x.y], [pto_max_y.x, pto_max_y.y])\n",
    "\n",
    "            if dist_xmax_ymax < dist_xmax_ymin:\n",
    "                v1 += 90\n",
    "\n",
    "            orientation_rf = 180 + np.degrees(v1.angle_signed([0, 1])) # to use the orientation estimated geometrically\n",
    "            \n",
    "            area_rf = detections.area[idx]\n",
    "\n",
    "            \n",
    "            # Create a temporary DataFrame for new row\n",
    "            df_temp = pd.DataFrame([{\n",
    "                \"image_name\": file_image,\n",
    "                \"coordinates\": coordinates[i],\n",
    "                \"area_rf\": area_rf,\n",
    "                \"orientation_rf\": orientation_rf,          \n",
    "            }])\n",
    "\n",
    "            # Concat temporary DataFrame with main df\n",
    "            df_results_rf = pd.concat([df_results_rf, df_temp], ignore_index=True)\n",
    "\n",
    "            #print(f\"Image: {file_image}, Coordinates: {coordinates[i]}º, Area: {area_rf} m2\")\n",
    "    else:\n",
    "        print(f\"File {file_image} does not exist\")\n",
    "\n",
    "print(f\"The Roboflow results dataframe has been created\")\n",
    "\n",
    "# Show the results DataFrame\n",
    "print(df_results_rf)\n",
    "\n",
    "# print (results)\n",
    "# print (detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9939233-9015-45f4-bfde-1ce97805c843",
   "metadata": {},
   "source": [
    "#### Almacenar fichero de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc14d48-74a0-42fa-a1a1-986cff71ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Roboflow results DataFrame\n",
    "\n",
    "# Save the DataFrame in a CSV in its file path\n",
    "df_results_rf.to_csv(file_path_results, index=False)\n",
    "\n",
    "print(f\"CSV file saved in '{folder}/{file_name_results}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc110571-8549-4c4f-8ac6-6ddafff02bf4",
   "metadata": {},
   "source": [
    "### Estimación generación PVLIB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a7945-e19b-46e8-bad0-e94265edd387",
   "metadata": {},
   "source": [
    "#### Definición de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995ee1b-de3e-468b-b2e3-23372d98f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvlib\n",
    "from pvlib.pvsystem import PVSystem, Array, FixedMount\n",
    "from pvlib.location import Location\n",
    "from pvlib.modelchain import ModelChain\n",
    "\n",
    "timezone = 'Europe/Madrid'\n",
    "temperature_model_parameters = pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']['insulated_back_glass_polymer'] #change temperature if desired\n",
    "# insulated_back_glass_polymer\n",
    "# open_rack_glass_polymer\n",
    "# open_rack_glass_glass\n",
    "# close_mount_glass_glass\n",
    "\n",
    "module_eff = 0.2\n",
    "gamma = -0.004 # module temperature coefficient for Power loss reduction\n",
    "eta_inv = 0.98 # inverter efficiency\n",
    "system_loss = 0.15  # general system losses (dust, electrical, missmatch, shadowing ...)\n",
    "\n",
    "area_ratio = 23.3 # Ratio between the output area of roboflow and the measured area in GMAPS, pixels/m\n",
    "\n",
    "orientation_deg = 180\n",
    "inclination_deg = 10\n",
    "\n",
    "print(f\"PV parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ecb8b-038f-46ef-b29c-aa61b5e49946",
   "metadata": {},
   "source": [
    "#### Estimación de la potencia instalada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227dcc1-2e28-446f-b880-5e3b7361bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate results DataFrame from Roboflow\n",
    "#df_predictions_pdc = df_results_rf #copy df\n",
    "df_predictions_pdc = pd.read_csv(file_path_results) #import df locally saved\n",
    "\n",
    "\n",
    "# Add columns for area in m2 and installed pdc\n",
    "df_predictions_pdc[\"area_m2\"] = 0.0\n",
    "df_predictions_pdc[\"pdc_kW\"] = 0.0\n",
    "\n",
    "# Define for each row the area and pdc\n",
    "for idx, row in df_predictions_pdc.iterrows():\n",
    "\n",
    "    df_predictions_pdc.at[idx, \"area_m2\"] = df_predictions_pdc.at[idx, \"area_rf\"] / area_ratio\n",
    "    df_predictions_pdc.at[idx, \"pdc_kW\"] = df_predictions_pdc.at[idx, \"area_m2\"] * module_eff\n",
    "\n",
    "print(f\"The prediction results dataframe with Pdc has been created\")\n",
    "\n",
    "# Show the DataFrame results for installed pdc\n",
    "print(df_predictions_pdc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6820ef3-2d21-4667-9b65-ada7e89b05f7",
   "metadata": {},
   "source": [
    "#### Almacenar fichero pdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c645a7-8cf2-46ee-98f7-fe0469aed2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Pdc predictions DataFrame\n",
    "\n",
    "# Save the DataFrame in a CSV in its file path\n",
    "df_predictions_pdc.to_csv(file_path_predictions_pdc, index=False)\n",
    "\n",
    "print(f\"CSV file saved in '{folder}/{file_name_predictions_pdc}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1be972-8c0b-4e43-9c69-9b5475955e38",
   "metadata": {},
   "source": [
    "#### Descarga de datos meteorológicos de PVGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578d582-a077-47ae-aa89-bbf086a1218a",
   "metadata": {},
   "source": [
    "**NO CORRER SI NO SE QUIERE HACER USO DE LA API DE PVGIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce7a7c-fafa-4da7-adb9-134ce622cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pvgis = pvlib.iotools.get_pvgis_tmy(latitud, longitud)[0]\n",
    "\n",
    "#print (weather_pvgis)\n",
    "print(f\"Weather data from PVGIS has been downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8883cdf-c587-4cae-a068-08d596e51f3b",
   "metadata": {},
   "source": [
    "#### Almacenar fichero meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee180e7-a105-44e4-aa14-6c74822fb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PVGis weather data\n",
    "\n",
    "# Save the DataFrame in a CSV in its file path\n",
    "weather_pvgis.to_csv(file_path_weather)\n",
    "\n",
    "print(f\"CSV file saved in '{folder}/{file_name_weather}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd0198-bd21-4fb4-b1ab-a5924c668cbf",
   "metadata": {},
   "source": [
    "#### Estimación energética"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a5efb-000d-4c18-a1a7-b8cbb1bff2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate DataFrame with results from pdc\n",
    "#df_predictions_eac = df_predictions_pdc #copy df\n",
    "df_predictions_eac = pd.read_csv(file_path_predictions_pdc) #import df locally saved\n",
    "\n",
    "# weather_imp = pd.read_csv(file_path_weather) # import pvgis file \n",
    "\n",
    "# Add columns for orientation, inclination and annual energy\n",
    "df_predictions_eac[\"orientation_deg\"] = orientation_deg #change for orientation_rf if desired\n",
    "df_predictions_eac[\"inclination_deg\"] = inclination_deg\n",
    "df_predictions_eac[\"annual_energy_kWh\"] = 0.0\n",
    "\n",
    "for idx, row in df_predictions_eac.iterrows():\n",
    "\n",
    "    #latitude, longitude = row[\"coordinates\"]   \n",
    "    surface_tilt = row[\"inclination_deg\"]\n",
    "    surface_azimuth = row[\"orientation_deg\"] \n",
    "    pdc = row[\"pdc_kW\"]\n",
    "  \n",
    "    module = {'pdc0': pdc, 'gamma_pdc': gamma}\n",
    "    inverter = {'pdc0': pdc, 'eta_inv_nom': eta_inv}\n",
    "\n",
    "    location = Location(\n",
    "        latitude=latitud, #coordinates from the center of GMAPS sweep\n",
    "        longitude=longitud,\n",
    "        tz=timezone,\n",
    "    )\n",
    "\n",
    "    #weather = pvlib.iotools.get_pvgis_tmy(latitude, longitude)\n",
    "    #If this option is used, many pvgis queries are made and for a small area it is better to take only the center of the main square coordinates\n",
    "    \n",
    "    weather = weather_pvgis # need to run the apicorrer la api\n",
    "    #weather = weather_imp #import df saved, not working by now\n",
    "    \n",
    "    mount = FixedMount(surface_tilt=surface_tilt, surface_azimuth=surface_azimuth)\n",
    "    \n",
    "    array = Array(\n",
    "        mount=mount,\n",
    "        module_parameters=module,\n",
    "        temperature_model_parameters=temperature_model_parameters,\n",
    "    )\n",
    "\n",
    "    system = PVSystem(arrays=[array], inverter_parameters=inverter)\n",
    "\n",
    "    mc = ModelChain(system, location, aoi_model='physical', spectral_model='no_loss')\n",
    "    mc.run_model(weather)\n",
    "\n",
    "    annual_energy_kWh = mc.results.ac.sum() * (1 - system_loss)\n",
    "\n",
    "    df_predictions_eac.at[idx, \"annual_energy_kWh\"] = annual_energy_kWh\n",
    "\n",
    "print(f\"The prediction results dataframe with annual Eac has been created\")\n",
    "\n",
    "# Show the DataFrame with annual energy results\n",
    "print(df_predictions_eac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb6c82-c689-46af-bfb5-a75bc94e6780",
   "metadata": {},
   "source": [
    "#### Almacenar fichero Eac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0065ab-6904-4ea7-9b39-8a20469cbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PVlib predictions DataFrame\n",
    "\n",
    "# Save the DataFrame in a CSV in its file path\n",
    "df_predictions_eac.to_csv(file_path_predictions_eac, index=False)\n",
    "\n",
    "print(f\"CSV file saved in '{folder}/{file_name_predictions_eac}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce3ba0-eaff-4591-97b9-9d57e4e2a2ca",
   "metadata": {},
   "source": [
    "# NOTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c84859-fb55-45f7-8805-0823e4de0e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd0368-2ad6-43ed-9f31-7073038a3581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
